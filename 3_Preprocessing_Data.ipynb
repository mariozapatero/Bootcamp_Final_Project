{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff638e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9b6eb",
   "metadata": {},
   "source": [
    "# Preprocessing Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ac0e6",
   "metadata": {},
   "source": [
    "En el preprocesado de los datos (transformaciones necesarias para incluir los datos en el modelo NLP, más allá de la limpieza desarrollado anteriormente), podemos diferenciar cuatro etapas básicas:\n",
    "- Tokenization: consiste en convertir los textos a objetos manejables por las librerías utilizadas.\n",
    "\n",
    "\n",
    "- Stop words removal: eliminamos las palabras clasificadas como *'stop words'* (palabras que aparecen comúnmente en los textos, pero que no aportan significado real en los mismos).\n",
    "\n",
    "\n",
    "- Lemmatization or Stemming: en principio utilizaremos lemmatization ya que suele obtener mejores resultados, pero sería conveniente probar los dos métodos y evaluar cuál ofrece un mayor rendimiento.\n",
    "\n",
    "Llevaremos a cabo estas transformaciones a partir de la función `preprocessing()` previamente definida en 'src/preprocessing_functions' (la función incluye todos las trasformaciones de preprocesado.\n",
    "\n",
    "A continuación se muestra el desarrollo de este proceso para nuestro dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "407580ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tweets = pd.read_csv('data/brands.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79802de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58556, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a194e990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text               2\n",
       "hashtags           0\n",
       "brand_attribute    0\n",
       "brand              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_tweets.isnull().sum() \n",
    "\n",
    "# Aparecen dos nulos que no tenemos en el csv original ('brands.csv').\n",
    "# Debe ser un problema de encoding o algo similar y, como son solo 2 sobre 58.556 filas, decidimos eliminarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c14299be",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tweets.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b2cee90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58554, 4)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64b50696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc849be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tweets['token'] = brand_tweets.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da89b0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>brand_attribute</th>\n",
       "      <th>brand</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nobody cares about nike in russia russia is al...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[care, nike, russia, russia, adidas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ye green nike hoodie waala two weeks pehle put...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[ye, green, nike, hoodie, waala, week, pehle, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nike okundaye also knowns nike twins seven sev...</td>\n",
       "      <td>['#womengiant', '#Documentwomen']</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[nike, okundaye, knowns, nike, twin, seven, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day four of maxmadness air max month nike air ...</td>\n",
       "      <td>['#maxmadness', '#AirMaxMonth', '#airmaxgang',...</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[day, maxmadness, air, max, month, nike, air, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank you sir</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[thank, sir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  nobody cares about nike in russia russia is al...   \n",
       "1  ye green nike hoodie waala two weeks pehle put...   \n",
       "2  nike okundaye also knowns nike twins seven sev...   \n",
       "3  day four of maxmadness air max month nike air ...   \n",
       "4                                      thank you sir   \n",
       "\n",
       "                                            hashtags brand_attribute brand  \\\n",
       "0                                                 []         quality  nike   \n",
       "1                                                 []         quality  nike   \n",
       "2                  ['#womengiant', '#Documentwomen']         quality  nike   \n",
       "3  ['#maxmadness', '#AirMaxMonth', '#airmaxgang',...         quality  nike   \n",
       "4                                                 []         quality  nike   \n",
       "\n",
       "                                               token  \n",
       "0               [care, nike, russia, russia, adidas]  \n",
       "1  [ye, green, nike, hoodie, waala, week, pehle, ...  \n",
       "2  [nike, okundaye, knowns, nike, twin, seven, se...  \n",
       "3  [day, maxmadness, air, max, month, nike, air, ...  \n",
       "4                                       [thank, sir]  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ba4b8",
   "metadata": {},
   "source": [
    "Exportamos los datos para proceder al análisis de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "893fdd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tweets.to_csv('data/brands_tokens.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
