{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4ec9df",
   "metadata": {},
   "source": [
    "### TextBlob (Spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb978e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTRO!!!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''INTRO!!!'''\n",
    "\n",
    "# Esplicación breve.\n",
    "\n",
    "# Catarse bien de cómo funciona.\n",
    "# Ojo instalaciones (lo he metido en todos laos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9207493e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['I', 'had', 'a']),\n",
       " WordList(['had', 'a', 'really']),\n",
       " WordList(['a', 'really', 'horrible']),\n",
       " WordList(['really', 'horrible', 'day']),\n",
       " WordList(['horrible', 'day', 'It']),\n",
       " WordList(['day', 'It', 'was']),\n",
       " WordList(['It', 'was', 'the']),\n",
       " WordList(['was', 'the', 'worst']),\n",
       " WordList(['the', 'worst', 'day']),\n",
       " WordList(['worst', 'day', 'ever']),\n",
       " WordList(['day', 'ever', 'But']),\n",
       " WordList(['ever', 'But', 'every']),\n",
       " WordList(['But', 'every', 'now']),\n",
       " WordList(['every', 'now', 'and']),\n",
       " WordList(['now', 'and', 'then']),\n",
       " WordList(['and', 'then', 'I']),\n",
       " WordList(['then', 'I', 'have']),\n",
       " WordList(['I', 'have', 'a']),\n",
       " WordList(['have', 'a', 'really']),\n",
       " WordList(['a', 'really', 'good']),\n",
       " WordList(['really', 'good', 'day']),\n",
       " WordList(['good', 'day', 'that']),\n",
       " WordList(['day', 'that', 'makes']),\n",
       " WordList(['that', 'makes', 'me']),\n",
       " WordList(['makes', 'me', 'happy'])]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\n",
    "doc = nlp(text)\n",
    "doc._.blob.polarity                            # Polarity: -0.125\n",
    "doc._.blob.subjectivity                        # Subjectivity: 0.9\n",
    "doc._.blob.sentiment_assessments.assessments   # Assessments: [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n",
    "doc._.blob.ngrams()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9678dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.125\n",
      "0.9\n",
      "[(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "print(blob.sentiment_assessments.polarity)\n",
    "# -0.125\n",
    "\n",
    "print(blob.sentiment_assessments.subjectivity)\n",
    "# 0.9\n",
    "\n",
    "print(blob.sentiment_assessments.assessments)\n",
    "# [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af519d24",
   "metadata": {},
   "source": [
    "### VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8e18f",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) es una librería utilizada para el análisis del sentimiento que se enfoca en los textos de social media. Así, pone énfases en las rules que captan la esencia del texto que normalmente se ve en las redes sociales. Realmente está pensado para actuar sobre texto que no han sido limpiados previamente (con emojis, signos de exclamación, etc.). Nosotros lo probaremos tanto sobre los datos ya limpios, como sobre los datos originales. Lo ideal sería evaluar la precisión de cada uno de ellos (junto con el análisis desarrollado mediante otros modelos), para identificar el que ofrece un mayor rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c5362",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0512e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc66d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "brands_tweets = pd.read_pickle('data/brands_tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b90c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>brand_attribute</th>\n",
       "      <th>brand</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nobody cares about nike in russia russia is al...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[care, nike, russia, russia, adidas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ye green nike hoodie waala two weeks pehle put...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[ye, green, nike, hoodie, waala, week, pehle, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nike okundaye also knowns nike twins seven sev...</td>\n",
       "      <td>['#womengiant', '#Documentwomen']</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[nike, okundaye, knowns, nike, twin, seven, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day four of maxmadness air max month nike air ...</td>\n",
       "      <td>['#maxmadness', '#AirMaxMonth', '#airmaxgang',...</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[day, maxmadness, air, max, month, nike, air, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank you sir</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[thank, sir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  nobody cares about nike in russia russia is al...   \n",
       "1  ye green nike hoodie waala two weeks pehle put...   \n",
       "2  nike okundaye also knowns nike twins seven sev...   \n",
       "3  day four of maxmadness air max month nike air ...   \n",
       "4                                      thank you sir   \n",
       "\n",
       "                                            hashtags brand_attribute brand  \\\n",
       "0                                                 []         quality  nike   \n",
       "1                                                 []         quality  nike   \n",
       "2                  ['#womengiant', '#Documentwomen']         quality  nike   \n",
       "3  ['#maxmadness', '#AirMaxMonth', '#airmaxgang',...         quality  nike   \n",
       "4                                                 []         quality  nike   \n",
       "\n",
       "                                               token  \n",
       "0               [care, nike, russia, russia, adidas]  \n",
       "1  [ye, green, nike, hoodie, waala, week, pehle, ...  \n",
       "2  [nike, okundaye, knowns, nike, twin, seven, se...  \n",
       "3  [day, maxmadness, air, max, month, nike, air, ...  \n",
       "4                                       [thank, sir]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e567fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_tweets['vader_scores'] = brands_tweets.token.apply(vader_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14576bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_tweets.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a51eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OJO QUE EN TEORÍA FUNCIONA MEJOR CON DATOS EN BRUTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71151b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
