{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10b8db5",
   "metadata": {},
   "source": [
    "### TextBlob (Spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23efdeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTRO!!!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''INTRO!!!'''\n",
    "\n",
    "# Esplicación breve.\n",
    "\n",
    "# Catarse bien de cómo funciona.\n",
    "# Ojo instalaciones (lo he metido en todos laos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6e6dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['I', 'had', 'a']),\n",
       " WordList(['had', 'a', 'really']),\n",
       " WordList(['a', 'really', 'horrible']),\n",
       " WordList(['really', 'horrible', 'day']),\n",
       " WordList(['horrible', 'day', 'It']),\n",
       " WordList(['day', 'It', 'was']),\n",
       " WordList(['It', 'was', 'the']),\n",
       " WordList(['was', 'the', 'worst']),\n",
       " WordList(['the', 'worst', 'day']),\n",
       " WordList(['worst', 'day', 'ever']),\n",
       " WordList(['day', 'ever', 'But']),\n",
       " WordList(['ever', 'But', 'every']),\n",
       " WordList(['But', 'every', 'now']),\n",
       " WordList(['every', 'now', 'and']),\n",
       " WordList(['now', 'and', 'then']),\n",
       " WordList(['and', 'then', 'I']),\n",
       " WordList(['then', 'I', 'have']),\n",
       " WordList(['I', 'have', 'a']),\n",
       " WordList(['have', 'a', 'really']),\n",
       " WordList(['a', 'really', 'good']),\n",
       " WordList(['really', 'good', 'day']),\n",
       " WordList(['good', 'day', 'that']),\n",
       " WordList(['day', 'that', 'makes']),\n",
       " WordList(['that', 'makes', 'me']),\n",
       " WordList(['makes', 'me', 'happy'])]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\n",
    "doc = nlp(text)\n",
    "doc._.blob.polarity                            # Polarity: -0.125\n",
    "doc._.blob.subjectivity                        # Subjectivity: 0.9\n",
    "doc._.blob.sentiment_assessments.assessments   # Assessments: [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n",
    "doc._.blob.ngrams()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a439c509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.125\n",
      "0.9\n",
      "[(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "print(blob.sentiment_assessments.polarity)\n",
    "# -0.125\n",
    "\n",
    "print(blob.sentiment_assessments.subjectivity)\n",
    "# 0.9\n",
    "\n",
    "print(blob.sentiment_assessments.assessments)\n",
    "# [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc382db",
   "metadata": {},
   "source": [
    "### VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a0dfc",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) es una librería utilizada para el análisis del sentimiento que se enfoca en los textos de social media. Así, pone énfases en las rules que captan la esencia del texto que normalmente se ve en las redes sociales. Realmente está pensado para actuar sobre texto que no han sido limpiados previamente (con emojis, signos de exclamación, etc.). Nosotros lo probaremos tanto sobre los datos ya limpios, como sobre los datos originales. Lo ideal sería evaluar la precisión de cada uno de ellos (junto con el análisis desarrollado mediante otros modelos), para identificar el que ofrece un mayor rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64cea0",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a507ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f34d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "brands_tweets = pd.read_pickle('data/brands_tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b481c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>brand_attribute</th>\n",
       "      <th>brand</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nobody cares about nike in russia russia is al...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[care, nike, russia, russia, adidas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ye green nike hoodie waala two weeks pehle put...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[ye, green, nike, hoodie, waala, week, pehle, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nike okundaye also knowns nike twins seven sev...</td>\n",
       "      <td>['#womengiant', '#Documentwomen']</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[nike, okundaye, knowns, nike, twin, seven, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day four of maxmadness air max month nike air ...</td>\n",
       "      <td>['#maxmadness', '#AirMaxMonth', '#airmaxgang',...</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[day, maxmadness, air, max, month, nike, air, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank you sir</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[thank, sir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  nobody cares about nike in russia russia is al...   \n",
       "1  ye green nike hoodie waala two weeks pehle put...   \n",
       "2  nike okundaye also knowns nike twins seven sev...   \n",
       "3  day four of maxmadness air max month nike air ...   \n",
       "4                                      thank you sir   \n",
       "\n",
       "                                            hashtags brand_attribute brand  \\\n",
       "0                                                 []         quality  nike   \n",
       "1                                                 []         quality  nike   \n",
       "2                  ['#womengiant', '#Documentwomen']         quality  nike   \n",
       "3  ['#maxmadness', '#AirMaxMonth', '#airmaxgang',...         quality  nike   \n",
       "4                                                 []         quality  nike   \n",
       "\n",
       "                                               token  \n",
       "0               [care, nike, russia, russia, adidas]  \n",
       "1  [ye, green, nike, hoodie, waala, week, pehle, ...  \n",
       "2  [nike, okundaye, knowns, nike, twin, seven, se...  \n",
       "3  [day, maxmadness, air, max, month, nike, air, ...  \n",
       "4                                       [thank, sir]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5121568",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_tweets['vader_scores'] = brands_tweets.token.apply(vader_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af78b60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>brand_attribute</th>\n",
       "      <th>brand</th>\n",
       "      <th>token</th>\n",
       "      <th>vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26586</th>\n",
       "      <td>the nike go flyease surfaces in another multic...</td>\n",
       "      <td>['#sneakersapp']</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[nike, flyease, surface, multicolor, sneakersapp]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7967</th>\n",
       "      <td>just in nike streetgato white lime glow</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[nike, streetgato, white, lime, glow]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>for the first time the fruity pebbles lebron f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[time, fruity, pebble, lebron, set, retail, re...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>nike ikea close russian stores as sanctions tr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>nike</td>\n",
       "      <td>[nike, ikea, close, russian, store, sanction, ...</td>\n",
       "      <td>{'neg': 0.208, 'neu': 0.792, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>sizes up to one two for the vast grey electric...</td>\n",
       "      <td>[]</td>\n",
       "      <td>price</td>\n",
       "      <td>nike</td>\n",
       "      <td>[size, vast, grey, electric, green, nike, spac...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.809, 'pos': 0.191, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47081</th>\n",
       "      <td>so dumb it s ike when people were burning thei...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>adidas</td>\n",
       "      <td>[dumb, ike, people, burning, nike, gear, like,...</td>\n",
       "      <td>{'neg': 0.525, 'neu': 0.35, 'pos': 0.125, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41527</th>\n",
       "      <td>my number one actually wore em to see batman t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>adidas</td>\n",
       "      <td>[number, actually, wore, em, batman, tuesday, ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.645, 'pos': 0.355, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38498</th>\n",
       "      <td>so good i had to share check out all the items...</td>\n",
       "      <td>['#poshmark', '#fashion', '#style', '#shopmycl...</td>\n",
       "      <td>quality</td>\n",
       "      <td>adidas</td>\n",
       "      <td>[good, share, check, item, loving, poshmark, f...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.383, 'pos': 0.617, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38801</th>\n",
       "      <td>ad dropped via nike us nike air sesh white var...</td>\n",
       "      <td>[]</td>\n",
       "      <td>quality</td>\n",
       "      <td>adidas</td>\n",
       "      <td>[ad, dropped, nike, nike, air, sesh, white, va...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.826, 'pos': 0.174, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39417</th>\n",
       "      <td>by any means supreme x nike sb dunk drops toda...</td>\n",
       "      <td>[]</td>\n",
       "      <td>price</td>\n",
       "      <td>adidas</td>\n",
       "      <td>[mean, supreme, x, nike, sb, dunk, drop, today...</td>\n",
       "      <td>{'neg': 0.128, 'neu': 0.305, 'pos': 0.567, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "26586  the nike go flyease surfaces in another multic...   \n",
       "7967             just in nike streetgato white lime glow   \n",
       "1476   for the first time the fruity pebbles lebron f...   \n",
       "4839   nike ikea close russian stores as sanctions tr...   \n",
       "26706  sizes up to one two for the vast grey electric...   \n",
       "47081  so dumb it s ike when people were burning thei...   \n",
       "41527  my number one actually wore em to see batman t...   \n",
       "38498  so good i had to share check out all the items...   \n",
       "38801  ad dropped via nike us nike air sesh white var...   \n",
       "39417  by any means supreme x nike sb dunk drops toda...   \n",
       "\n",
       "                                                hashtags brand_attribute  \\\n",
       "26586                                   ['#sneakersapp']         quality   \n",
       "7967                                                  []         quality   \n",
       "1476                                                  []         quality   \n",
       "4839                                                  []         quality   \n",
       "26706                                                 []           price   \n",
       "47081                                                 []         quality   \n",
       "41527                                                 []         quality   \n",
       "38498  ['#poshmark', '#fashion', '#style', '#shopmycl...         quality   \n",
       "38801                                                 []         quality   \n",
       "39417                                                 []           price   \n",
       "\n",
       "        brand                                              token  \\\n",
       "26586    nike  [nike, flyease, surface, multicolor, sneakersapp]   \n",
       "7967     nike              [nike, streetgato, white, lime, glow]   \n",
       "1476     nike  [time, fruity, pebble, lebron, set, retail, re...   \n",
       "4839     nike  [nike, ikea, close, russian, store, sanction, ...   \n",
       "26706    nike  [size, vast, grey, electric, green, nike, spac...   \n",
       "47081  adidas  [dumb, ike, people, burning, nike, gear, like,...   \n",
       "41527  adidas  [number, actually, wore, em, batman, tuesday, ...   \n",
       "38498  adidas  [good, share, check, item, loving, poshmark, f...   \n",
       "38801  adidas  [ad, dropped, nike, nike, air, sesh, white, va...   \n",
       "39417  adidas  [mean, supreme, x, nike, sb, dunk, drop, today...   \n",
       "\n",
       "                                            vader_scores  \n",
       "26586  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "7967   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1476   {'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'comp...  \n",
       "4839   {'neg': 0.208, 'neu': 0.792, 'pos': 0.0, 'comp...  \n",
       "26706  {'neg': 0.0, 'neu': 0.809, 'pos': 0.191, 'comp...  \n",
       "47081  {'neg': 0.525, 'neu': 0.35, 'pos': 0.125, 'com...  \n",
       "41527  {'neg': 0.0, 'neu': 0.645, 'pos': 0.355, 'comp...  \n",
       "38498  {'neg': 0.0, 'neu': 0.383, 'pos': 0.617, 'comp...  \n",
       "38801  {'neg': 0.0, 'neu': 0.826, 'pos': 0.174, 'comp...  \n",
       "39417  {'neg': 0.128, 'neu': 0.305, 'pos': 0.567, 'co...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands_tweets.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0142db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OJO QUE EN TEORÍA FUNCIONA MEJOR CON DATOS EN BRUTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed354d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
